{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Model Using Single LSTM Unit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjali-rgpt/Autocomplete/blob/master/Neural_Model_Using_Single_LSTM_Unit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhw5E3tjzGgk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fca0af32-1640-4bec-bd33-9951a2dceaec"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import random, sys"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_Lj6LT-zgxy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "00807645-20f5-46be-cef8-343486c5e3f0"
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7euS-U5zxtG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a7feef2-7483-4838-d5fc-458c7e996858"
      },
      "source": [
        "# import data \n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# text = text[:round(len(text)/2)]\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDYwDUnWImy5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7773e148-50fd-479a-8059-6b2d98e4f4ce"
      },
      "source": [
        "text = text[:1000]\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print('Vocabulary:', len(chars))\n",
        "# char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "# indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "  sentences.append(text[i: i + maxlen])\n",
        "  next_chars.append(text[i + maxlen])\n",
        "print('Number of sequences: ', len(sentences))\n",
        "\n",
        "# x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "# y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "# for i, sentence in enumerate(sentences):\n",
        "#   for t, char in enumerate(sentence):\n",
        "#       x[i, t, char_indices[char]] = 1\n",
        "#   y[i, char_indices[next_chars[i]]] = 1\n",
        "# print('Vectorised!')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary: 46\n",
            "Number of sequences:  320\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f4qWQpyTHm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "vocab_size = len(chars)\n",
        "\n",
        "X_train, X_test , y_train, y_test = train_test_split(sentences, next_chars , test_size = 0.2)\n",
        "\n",
        "X_train = [one_hot(d, vocab_size,filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',lower=True, split=' ') for d in X_train]  #remove punctuation\n",
        "X_test = [one_hot(d, vocab_size,filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',lower=True, split=' ') for d in X_test]\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=maxlen, padding='pre')\n",
        "X_test = pad_sequences(X_test, maxlen=maxlen, padding='pre')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ33KByyS_jT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.asarray(y_train)\n",
        "y_test = np.asarray(y_test)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEZWyjJ5Tpvy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3daa621-300d-4572-bb16-43848367fcdb"
      },
      "source": [
        "print('Build model...')\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(len(chars), 1, input_length=maxlen))\n",
        "model.add(tf.keras.layers.LSTM(8, input_shape=(maxlen, len(chars))))\n",
        "model.add(tf.keras.layers.Dense(len(chars), activation='softmax'))\n",
        "\n",
        "# optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHK8iSLGUTmt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb2376c5-f9bf-4204-c3be-4b4e2761e6b7"
      },
      "source": [
        "model.fit(X_train, y_train,batch_size=64,epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCIiji8dUC86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0uEfd0wY0Gu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tANNkxV7tbY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display():\n",
        "  start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "  for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "\n",
        "    for i in range(50):\n",
        "      x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "      for t, char in enumerate(sentence):\n",
        "        x_pred[0, t, char_indices[char]] = 1.\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds, diversity)\n",
        "        next_char = indices_char[next_index]\n",
        "        sentence = sentence[1:] + next_char\n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "      print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqU2FacGtdqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIwe7Y-7sYYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, to_file='textgenmodel.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF6o332xtyqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}